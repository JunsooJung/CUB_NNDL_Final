{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vit-pytorch\n",
      "  Downloading vit_pytorch-1.10.1-py3-none-any.whl.metadata (69 kB)\n",
      "     ---------------------------------------- 0.0/69.7 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/69.7 kB ? eta -:--:--\n",
      "     ---------------- --------------------- 30.7/69.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 69.7/69.7 kB 540.4 kB/s eta 0:00:00\n",
      "Collecting einops>=0.7.0 (from vit-pytorch)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: torch>=1.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from vit-pytorch) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from vit-pytorch) (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10->vit-pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.10->vit-pytorch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->vit-pytorch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->vit-pytorch) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.3)\n",
      "Downloading vit_pytorch-1.10.1-py3-none-any.whl (140 kB)\n",
      "   ---------------------------------------- 0.0/140.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 140.8/140.8 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.4/64.4 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: einops, vit-pytorch\n",
      "Successfully installed einops-0.8.1 vit-pytorch-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install vit-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be determined as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 4081 image(s) for Anas_platyrhynchos, CSV rows: 4081\n",
      "Copied 4929 image(s) for Ardea_herodias, CSV rows: 4932\n",
      "Copied 5000 image(s) for Bombycilla_cedrorum, CSV rows: 5000\n",
      "Copied 4821 image(s) for Branta_canadensis, CSV rows: 4821\n",
      "Copied 4823 image(s) for Bubo_virginianus, CSV rows: 4823\n",
      "Copied 4952 image(s) for Buteo_jamaicensis, CSV rows: 4952\n",
      "Copied 5000 image(s) for Calidris_alba, CSV rows: 5000\n",
      "Copied 3990 image(s) for Cardinalis_cardinalis, CSV rows: 3990\n",
      "Copied 4998 image(s) for Cathartes_aura, CSV rows: 4998\n",
      "Copied 4929 image(s) for Coragyps_atratus, CSV rows: 4929\n",
      "Copied 4821 image(s) for Corvus_cornix, CSV rows: 4821\n",
      "Copied 4989 image(s) for Dryocopus_pileatus, CSV rows: 4989\n",
      "Copied 4967 image(s) for Falco_sparverius, CSV rows: 4967\n",
      "Copied 4993 image(s) for Icterus_galbula, CSV rows: 4993\n",
      "Copied 4890 image(s) for Parus_major, CSV rows: 4890\n",
      "Copied 4973 image(s) for Passer_domesticus, CSV rows: 4974\n",
      "Copied 4999 image(s) for Quiscalus_mexicanus, CSV rows: 4999\n",
      "Copied 4995 image(s) for Sialia_sialis, CSV rows: 4995\n",
      "Copied 4978 image(s) for Sturnus_vulgaris, CSV rows: 4978\n",
      "Copied 4691 image(s) for Turdus_merula, CSV rows: 4691\n",
      "Copied 4991 image(s) for Turdus_migratorius, CSV rows: 4992\n",
      "Copied 4996 image(s) for Zenaida_macroura, CSV rows: 4996\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#                               Data Cleaning                                            #\n",
    "##########################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "base_path = r\"C:\\Users\\admin\\OneDrive\\Documents\\results\"\n",
    "output_path = r\"C:\\Users\\admin\\OneDrive\\Documents\\filtered_species\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "species_list = [\n",
    "    \"Anas_platyrhynchos\", \"Ardea_herodias\", \"Bombycilla_cedrorum\", \"Branta_canadensis\",\n",
    "    \"Bubo_virginianus\", \"Buteo_jamaicensis\", \"Calidris_alba\", \"Cardinalis_cardinalis\",\n",
    "    \"Cathartes_aura\", \"Coragyps_atratus\", \"Corvus_cornix\", \"Dryocopus_pileatus\",\n",
    "    \"Falco_sparverius\", \"Icterus_galbula\", \"Parus_major\", \"Passer_domesticus\",\n",
    "    \"Quiscalus_mexicanus\", \"Sialia_sialis\", \"Sturnus_vulgaris\", \"Turdus_merula\",\n",
    "    \"Turdus_migratorius\", \"Zenaida_macroura\"\n",
    "]\n",
    "\n",
    "for species in species_list:\n",
    "    species_name = species.replace(\"_\", \" \")\n",
    "    metadata_file = os.path.join(base_path, f\"{species}_metadata.csv\")\n",
    "    image_folder = os.path.join(base_path, f\"{species}_images\")\n",
    "    output_image_folder = os.path.join(output_path, f\"{species}_filtered_images\")\n",
    "    output_csv_file = os.path.join(output_path, f\"{species}_filtered_metadata.csv\")\n",
    "    os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "    # CSV recreate\n",
    "    df = pd.read_csv(metadata_file, encoding=\"latin1\")\n",
    "    df_filtered = df[df[\"species_name\"] == species_name]\n",
    "    df_filtered[[\"species_name\", \"observation_id\"]].to_csv(output_csv_file, index=False)\n",
    "\n",
    "    # Image copy\n",
    "    observation_ids = df_filtered[\"observation_id\"].astype(str).tolist()\n",
    "    image_files = os.listdir(image_folder)\n",
    "    copied = 0\n",
    "\n",
    "    for obs_id in observation_ids:\n",
    "        match_suffix = f\"_{obs_id}_0.jpeg\"\n",
    "        matched_files = [f for f in image_files if f.endswith(match_suffix)]\n",
    "\n",
    "        for file in matched_files:\n",
    "            src = os.path.join(image_folder, file)\n",
    "            dst = os.path.join(output_image_folder, file)\n",
    "            try:\n",
    "                shutil.copyfile(src, dst)\n",
    "                copied += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {e}\")\n",
    "\n",
    "    print(f\"Copied {copied} image(s) for {species}, CSV rows: {len(df_filtered)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ardea_herodias — CSV: 4932, Images: 4929, Missing: 3 → ['2651283', '3284364', '97898']\n",
      "Passer_domesticus — CSV: 4974, Images: 4973, Missing: 1 → ['2966935']\n",
      "Turdus_migratorius — CSV: 4992, Images: 4991, Missing: 1 → ['3629725']\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#                               Data Verifying                                           #\n",
    "##########################################################################################\n",
    "\n",
    "for species in species_list:\n",
    "    csv_path = os.path.join(output_path, f\"{species}_filtered_metadata.csv\")\n",
    "    img_path = os.path.join(output_path, f\"{species}_filtered_images\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    csv_obs_ids = set(df[\"observation_id\"].astype(str))\n",
    "    image_obs_ids = set()\n",
    "\n",
    "    for filename in os.listdir(img_path):\n",
    "        if filename.endswith(\"_0.jpeg\"):\n",
    "            parts = filename.split(\"_\")\n",
    "            try:\n",
    "                obs_id = parts[-2]\n",
    "                image_obs_ids.add(obs_id)\n",
    "            except IndexError:\n",
    "                print(f\"Invalid filename: {filename}\")\n",
    "\n",
    "    missing = csv_obs_ids - image_obs_ids\n",
    "    extra = image_obs_ids - csv_obs_ids\n",
    "\n",
    "    if missing:\n",
    "        print(f\"{species} — CSV: {len(csv_obs_ids)}, Images: {len(image_obs_ids)}, Missing: {len(missing)} → {list(missing)[:5]}{'...' if len(missing) > 5 else ''}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: Ardea_herodias — removed 3 rows\n",
      "Cleaned: Passer_domesticus — removed 1 rows\n",
      "Cleaned: Turdus_migratorius — removed 1 rows\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#                               Handle inaccurate part                                   #\n",
    "##########################################################################################\n",
    "missing_data = {\n",
    "    \"Ardea_herodias\": [\"97898\", \"2651283\", \"3284364\"],\n",
    "    \"Passer_domesticus\": [\"2966935\"],\n",
    "    \"Turdus_migratorius\": [\"3629725\"]\n",
    "}\n",
    "\n",
    "for species, missing_ids in missing_data.items():\n",
    "    csv_path = f\"{output_path}/{species}_filtered_metadata.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_cleaned = df[~df[\"observation_id\"].astype(str).isin(missing_ids)]\n",
    "    df_cleaned.to_csv(csv_path, index=False)\n",
    "    print(f\"Cleaned: {species} — removed {len(missing_ids)} rows\")\n",
    "\n",
    "# Run previous block to verify there is no output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Running Cleaning Code, Should be Good to Start From Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "output_path = r\"C:\\Users\\admin\\OneDrive\\Documents\\filtered_species\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),  #Resize to minimum of all sizes - Will update size in cnn architecture\n",
    "    #transforms.Normalize(),\n",
    "    transforms.RandomHorizontalFlip(p = 0.25),\n",
    "    transforms.RandomRotation(degrees = 30),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root=output_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "training, testing = random_split(data, [train_size, test_size], generator=torch.Generator().manual_seed(1111))\n",
    "\n",
    "training_dataset = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
    "testing_dataset = DataLoader(testing, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "#For testing purposes\n",
    "#print(\"Class names:\", data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.4471, 0.4431,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.4471, 0.4471,  ..., 0.5686, 0.5647, 0.5843],\n",
       "           [0.0000, 0.4392, 0.4392,  ..., 0.5725, 0.5725, 0.5922],\n",
       "           ...,\n",
       "           [0.6667, 0.6667, 0.6627,  ..., 0.8039, 0.8000, 0.0000],\n",
       "           [0.6392, 0.6353, 0.6392,  ..., 0.7843, 0.7843, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.7843, 0.7882, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.4667, 0.4627,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.4667, 0.4667,  ..., 0.5961, 0.5922, 0.6118],\n",
       "           [0.0000, 0.4588, 0.4588,  ..., 0.6000, 0.6000, 0.6196],\n",
       "           ...,\n",
       "           [0.7686, 0.7686, 0.7647,  ..., 0.8039, 0.8000, 0.0000],\n",
       "           [0.7412, 0.7373, 0.7412,  ..., 0.7843, 0.7843, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.7843, 0.7882, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.4784, 0.4745,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.4784, 0.4784,  ..., 0.6353, 0.6314, 0.6510],\n",
       "           [0.0000, 0.4706, 0.4706,  ..., 0.6392, 0.6392, 0.6588],\n",
       "           ...,\n",
       "           [0.8980, 0.8980, 0.8941,  ..., 0.8039, 0.8000, 0.0000],\n",
       "           [0.8706, 0.8667, 0.8706,  ..., 0.7843, 0.7843, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.7843, 0.7882, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n",
       " tensor([18, 21,  2, 14, 12, 10,  8,  7, 12, 11, 15,  0,  8, 13,  8,  1, 10, 11,\n",
       "         16, 11, 21, 18, 20, 16, 16, 19, 10,  4, 18, 18,  3,  8])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(training_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vit_pytorch import ViT\n",
    "from vit_pytorch.vit import Transformer, Attention\n",
    "\n",
    "\n",
    "class BirdClassifier(nn.Module):\n",
    "    #donot adjust the patch size, thats what the cnn is for\n",
    "    def __init__(self, \n",
    "                 cnn_state=False, \n",
    "                 image_size=256, \n",
    "                 patch_size = 1, \n",
    "                 num_class = 22, \n",
    "                 dim = 1056, \n",
    "                 layer_count = 1,\n",
    "                 head_count = 1,\n",
    "                 transformer_ff_neurons = 1056,\n",
    "                 transformer_dropout = 0.1\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.cnn_state = cnn_state\n",
    "\n",
    "        dummy_input = torch.zeros(1, 3, image_size, image_size)\n",
    "\n",
    "        if self.cnn_state:\n",
    "            #the following architecture is alexnet -> For test one cnn_state should be flase\n",
    "            self.cnn = nn.Sequential(\n",
    "                nn.ReLU(nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)),\n",
    "                nn.ReLU(nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)),\n",
    "                nn.ReLU(nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)),\n",
    "                nn.ReLU(nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)),\n",
    "                nn.ReLU(nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)),\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                cnn_out = self.cnn(dummy_input)\n",
    "                _, out_channels, out_height, out_width = cnn_out.shape\n",
    "                vit_input_size = max(out_height, out_width)\n",
    "                vit_input_channels = out_channels  \n",
    "                          \n",
    "        else:\n",
    "            # No CNN — raw input goes to ViT\n",
    "            vit_input_size = image_size\n",
    "            vit_input_channels = 3\n",
    "\n",
    "        self.vision_transformer = ViT(\n",
    "            image_size = vit_input_size,\n",
    "            patch_size = 1,\n",
    "            num_classes = num_class,\n",
    "            dim = dim, #embedding in attention\n",
    "            depth = layer_count, #layers in transformer _> testing this in test 1 in proposal\n",
    "            heads = head_count, #testing thos in test 1 in proposal\n",
    "            mlp_dim = transformer_ff_neurons, #size of mlp try to change to see if wecan make this deeper, will likely need to imple,ent transformer by hand if so - 1056 or 512 could work\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1,\n",
    "            channels = vit_input_channels\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cnn_state:\n",
    "            x = self.cnn(x)\n",
    "        x = self.vision_transformer(x)\n",
    "\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 30.7/57.7 kB 325.1 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 51.2/57.7 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 431.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install torchmetrics\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import Accuracy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer_metric, accuracy_metric, device):\n",
    "    model.train()\n",
    "    net_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc = \"TRAINIGN\"):\n",
    "        image, label = images.to(device), labels.to(device)\n",
    "        y_hat = model(image)\n",
    "        loss = criterion(y_hat, label)\n",
    "        optimizer_metric.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_metric.step()\n",
    "        accuracy_metric.update(y_hat, label)\n",
    "        net_loss += loss.item()\n",
    "    \n",
    "    epoch_accuracy = accuracy_metric.compute().item()\n",
    "    epoch_loss = net_loss/(len(dataloader))\n",
    "\n",
    "    return epoch_accuracy, epoch_loss\n",
    "\n",
    "def test_model(model, dataloader, criterion, accuracy_metric, device):\n",
    "    model.eval()\n",
    "    net_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc = \"TESTING\"):\n",
    "        image, label = images.to(device), labels.to(device)\n",
    "        y_hat = model(image)\n",
    "        loss = criterion(y_hat, label)\n",
    "        accuracy_metric.update(y_hat, label)\n",
    "        net_loss += loss.item()\n",
    "    \n",
    "    epoch_accuracy = accuracy_metric.compute().item()\n",
    "    epoch_loss = net_loss/(len(dataloader))\n",
    "\n",
    "    return epoch_accuracy, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BirdClassifier(cnn_state=False).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "accuracy_score = Accuracy(task = 'multiclass', num_classes = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN:   0%|          | 0/2671 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loss_scores_train = []\n",
    "accuracy_scores_train = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    accuracy_score.reset()\n",
    "    trained = train_model(model, dataloader = training_dataset, criterion = criterion, optimizer_metric = optimizer, accuracy_metric=accuracy_score, device = device)\n",
    "    accuracy_scores_train.append(trained[0])\n",
    "    loss_scores_train.append(trained[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ViT\n",
    "\n",
    "set cnn_state to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_scores_test = []\n",
    "accuracy_scores_test = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    accuracy_score.reset()\n",
    "    trained = train_model(model, dataloader = training_dataset, criterion = criterion, optimizer_metric = optimizer, accuracy_metric=accuracy_score, device = device)\n",
    "    accuracy_scores_test.append(trained[0])\n",
    "    loss_scores_test.append(trained[1])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
