{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e818c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader,Subset,random_split\n",
    "from vit_pytorch import ViT\n",
    "from vit_pytorch.vit import Transformer, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79977fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"filtered_species\"\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),  #Resize to minimum of all sizes - Will update size in cnn architecture\n",
    "    transforms.RandomHorizontalFlip(p = 0.25),\n",
    "    transforms.RandomRotation(degrees = 30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "\n",
    "subset_size = 5000\n",
    "indices = random.sample(range(len(data)), subset_size)\n",
    "data_subset = Subset(data, indices)\n",
    "\n",
    "#change data_subset <-> data for train from whole data\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "training, testing = random_split(data, [train_size, test_size], generator=torch.Generator().manual_seed(1111))\n",
    "\n",
    "training_dataset = DataLoader(training, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "testing_dataset = DataLoader(testing, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "#For testing purposes\n",
    "#print(\"Class names:\", data.classes)\n",
    "#len(data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a6a1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 cnn_state=False,                # Whether to use CNN before ViT\n",
    "                 image_size=256,\n",
    "                 patch_size=16,\n",
    "                 num_class=10,\n",
    "                 dim=256,\n",
    "                 layer_count=1,\n",
    "                 head_count=1,\n",
    "                 transformer_ff_neurons=256,\n",
    "                 transformer_dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_state = cnn_state\n",
    "        self.image_size = image_size if not cnn_state else 64  # Will update if CNN is used\n",
    "\n",
    "        if cnn_state:\n",
    "            self.cnn = nn.Sequential(\n",
    "                nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),  # AlexNet\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                \n",
    "                nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "                nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((self.image_size, self.image_size))  # Resize to ViT input\n",
    "            )\n",
    "\n",
    "        self.vision_transformer = ViT(\n",
    "            image_size=self.image_size,\n",
    "            patch_size=patch_size,\n",
    "            num_classes=num_class,\n",
    "            dim=dim,\n",
    "            depth=layer_count,\n",
    "            heads=head_count,\n",
    "            mlp_dim=transformer_ff_neurons,\n",
    "            dropout=transformer_dropout,\n",
    "            emb_dropout=transformer_dropout,\n",
    "            channels=3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.cnn_state:\n",
    "            x = self.cnn(x)\n",
    "        x = self.vision_transformer(x)\n",
    "        return x\n",
    "\n",
    "    def print_config(self):\n",
    "        print(f\"Using CNN: {self.cnn_state}\")\n",
    "        print(f\"ViT dim: {self.vision_transformer.dim}, layers: {self.vision_transformer.depth}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5826d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer_metric, accuracy_metric, device):\n",
    "    model.train()\n",
    "    net_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc = \"TRAINIGN\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y_hat = model(images)\n",
    "        loss = criterion(y_hat, labels)\n",
    "        optimizer_metric.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_metric.step()\n",
    "        accuracy_metric.update(y_hat, labels)\n",
    "        net_loss += loss.item()\n",
    "    \n",
    "    epoch_accuracy = accuracy_metric.compute().item()\n",
    "    epoch_loss = net_loss/(len(dataloader))\n",
    "\n",
    "    return epoch_accuracy, epoch_loss\n",
    "\n",
    "def test_model(model, dataloader, criterion, accuracy_metric, device):\n",
    "    model.eval()\n",
    "    net_loss = 0\n",
    "    for images, labels in tqdm(dataloader, desc = \"TESTING\"):\n",
    "        image, label = images.to(device), labels.to(device)\n",
    "        y_hat = model(image)\n",
    "        loss = criterion(y_hat, label)\n",
    "        accuracy_metric.update(y_hat, label)\n",
    "        net_loss += loss.item()\n",
    "    \n",
    "    epoch_accuracy = accuracy_metric.compute().item()\n",
    "    epoch_loss = net_loss/(len(dataloader))\n",
    "\n",
    "    return epoch_accuracy, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc44cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:33<00:00, 17.58it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3142 | Train Loss: 1.9243 | Test Acc: 0.3266 | Test Loss: 1.7574983113477018\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.11it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3478 | Train Loss: 1.7610 | Test Acc: 0.3519 | Test Loss: 1.8013007884122887\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.08it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3670 | Train Loss: 1.6857 | Test Acc: 0.3712 | Test Loss: 1.6218019140009978\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 17.97it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3824 | Train Loss: 1.6397 | Test Acc: 0.3857 | Test Loss: 1.5892163588076222\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.32it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3950 | Train Loss: 1.5990 | Test Acc: 0.3974 | Test Loss: 1.567760478071615\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.23it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4046 | Train Loss: 1.5653 | Test Acc: 0.4063 | Test Loss: 1.5496198247079136\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.06it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4132 | Train Loss: 1.5354 | Test Acc: 0.4151 | Test Loss: 1.5100424265374943\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.28it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4209 | Train Loss: 1.5116 | Test Acc: 0.4219 | Test Loss: 1.5585161050160725\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.11it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4273 | Train Loss: 1.4848 | Test Acc: 0.4286 | Test Loss: 1.466239907303635\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.10it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4337 | Train Loss: 1.4585 | Test Acc: 0.4349 | Test Loss: 1.4541337652271296\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.24it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4393 | Train Loss: 1.4460 | Test Acc: 0.4405 | Test Loss: 1.4191117416433736\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.22it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4447 | Train Loss: 1.4230 | Test Acc: 0.4458 | Test Loss: 1.4387104989720039\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.15it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:07<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4498 | Train Loss: 1.4044 | Test Acc: 0.4507 | Test Loss: 1.4480376592298754\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:32<00:00, 18.00it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4543 | Train Loss: 1.3946 | Test Acc: 0.4553 | Test Loss: 1.3918831299762338\n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:31<00:00, 18.37it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:05<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4589 | Train Loss: 1.3721 | Test Acc: 0.4598 | Test Loss: 1.3709381028097503\n",
      "\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN: 100%|██████████| 587/587 [00:31<00:00, 18.40it/s]\n",
      "TESTING: 100%|██████████| 147/147 [00:06<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4633 | Train Loss: 1.3543 | Test Acc: 0.4642 | Test Loss: 1.375197401663073\n",
      "\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINIGN:  26%|██▌       | 154/587 [00:09<00:25, 16.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m200\u001b[39m):  \n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     train_acc, train_loss = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_multihead_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     test_acc, test_loss = test_model(model_multihead_8, testing_dataset, criterion, accuracy_score, device)\n\u001b[32m     25\u001b[39m     accuracy_scores_train_multihead_8.append(train_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer_metric, accuracy_metric, device)\u001b[39m\n\u001b[32m     10\u001b[39m     optimizer_metric.step()\n\u001b[32m     11\u001b[39m     accuracy_metric.update(y_hat, labels)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     net_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m epoch_accuracy = accuracy_metric.compute().item()\n\u001b[32m     15\u001b[39m epoch_loss = net_loss/(\u001b[38;5;28mlen\u001b[39m(dataloader))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_multihead_8 = BirdClassifier(cnn_state=False, layer_count=4, head_count = 8).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model_multihead_8.parameters(), lr=3e-4)\n",
    "accuracy_score = Accuracy(task = 'multiclass', num_classes = 10).to(device)\n",
    "\n",
    "\n",
    "patience = 3\n",
    "min_delta = 3e-3\n",
    "best_accuracy = 0\n",
    "counter = 0\n",
    "\n",
    "loss_scores_train_multihead_8 = []\n",
    "accuracy_scores_train_multihead_8 = []\n",
    "\n",
    "loss_scores_test_multihead_8 = []\n",
    "accuracy_scores_test_multihead_8 = []\n",
    "\n",
    "for epoch in range(200):  \n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    train_acc, train_loss = train_model(model_multihead_8, training_dataset, criterion, optimizer, accuracy_score, device)\n",
    "    test_acc, test_loss = test_model(model_multihead_8, testing_dataset, criterion, accuracy_score, device)\n",
    "    \n",
    "    accuracy_scores_train_multihead_8.append(train_acc)\n",
    "    loss_scores_train_multihead_8.append(train_loss)\n",
    "\n",
    "    accuracy_scores_test_multihead_8.append(test_acc)\n",
    "    loss_scores_test_multihead_8.append(test_loss)\n",
    "    print(f\"Train Acc: {train_acc:.4f} | Train Loss: {train_loss:.4f} | Test Acc: {test_acc:.4f} | Test Loss: {test_loss}\")\n",
    "    \n",
    "    if test_acc - best_test_acc > min_delta:\n",
    "        best_test_acc = test_acc\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement. Early stopping counter: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
